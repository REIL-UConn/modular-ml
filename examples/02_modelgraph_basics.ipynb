{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552cc21a",
   "metadata": {},
   "source": [
    "---\n",
    "# 02_modelgraph_basics.ipynb\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33fa5ee",
   "metadata": {},
   "source": [
    "## Building a ModelGraph\n",
    "\n",
    "One of the most powerful aspects of ModularML is its `ModelGraph` abstraction, which represents a directed-acyclic-graph (DAG) of computation. This structure allows multiple `ModelStage` instances to be flexibly connected into a larger model pipeline.\n",
    "\n",
    "Each `ModelStage` can use any supported backend, such as PyTorch, TensorFlow/Keras, or Scikit-learn. This enables the creation of complex multi-objective modeling workflows using a unified interface.\n",
    "\n",
    "In this example, we demonstrate a two-stage modeling pipeline: a CNN encoder processes input voltage features into a latent embedding, followed by an MLP regressor that estimates the battery state-of-health (SOH) from this embedding.\n",
    "\n",
    "ModularML provides pre-built classes for commonly used model types such as sequential CNNs and MLPs. While we use those here, any custom model can be integrated by subclassing `modularml.BaseModel` and implementing the required methods.\n",
    "\n",
    "Let's import the necessary components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b71a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modularml as mml\n",
    "from modularml.core import FeatureSet, ModelGraph, ModelStage, Optimizer\n",
    "from modularml.models.torch import SequentialCNN, SequentialMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec115725",
   "metadata": {},
   "source": [
    "We will be utilizing the FeatureSet created from the [01_featureset_basics.ipynb](./01_featureset_basics.ipynb) notebook. \n",
    "\n",
    "Let's reload that FeatureSet and underlying FeatureTransforms from the `.joblib` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b2d940d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureSet(label='ChargePulseFeatures', n_samples=12024)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "FILE_FEATURE_SET = Path(\"downloaded_data/charge_samples.joblib\")\n",
    "charge_samples = FeatureSet.load(FILE_FEATURE_SET)\n",
    "charge_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b539969",
   "metadata": {},
   "source": [
    "Now we can start creating our `ModelStages`.\n",
    "\n",
    "The `modularml.models` module provides convenient, pre-built implementations such as `SequentialCNN` and `SequentialMLP`, which allow for rapid prototyping of convolutional and dense architectures with configurable layer depth and hidden sizes. Please refer to the module documentation for a full list of available initialization parameters.\n",
    "\n",
    "A key feature of the `ModelStage` abstraction is its support for **lazy shape inference**. Input and output shapes do not need to be explicitly specified during model construction. Instead, ModularML dynamically infers the required shapes at runtime based on how FeatureSets and other ModelStages are connected in the ModelGraph.\n",
    "\n",
    "While input shape inference is automatic, it is generally advisable to specify the desired output shape for clarity and to avoid unintended behavior.\n",
    "\n",
    "To construct a `ModelStage`, the following arguments are required:\n",
    "\n",
    "* `model`: The machine learning model to be wrapped, which must inherit from `BaseModel`.\n",
    "\n",
    "* `label`: A unique string identifier for the stage.\n",
    "\n",
    "* `upstream_node`: The nodes that feed into this stage. Can be the label (str) of such nodes, or the nodes themselves.\n",
    "\n",
    "* `optimizer`: An optional `Optimizer` object used for training, required if the model parameters are to be updated during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c345273",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_encoder = ModelStage(\n",
    "    model=SequentialCNN(output_shape=(1, 32), n_layers=2, hidden_dim=16, flatten_output=True),\n",
    "    label=\"Encoder\",\n",
    "    upstream_node=\"ChargePulseFeatures\",  # Note that we could also pass the charge_samples object itself\n",
    "    optimizer=Optimizer(name=\"adam\", backend=mml.Backend.TORCH),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4632a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_regressor = ModelStage(\n",
    "    model=SequentialMLP(output_shape=(1, 1), n_layers=2, hidden_dim=16),\n",
    "    label=\"Regressor\",\n",
    "    upstream_node=ms_encoder,\t\t# Here, we pass the encoder object itself, but we could also use the string 'Encoder'\n",
    "    optimizer=Optimizer(name=\"adam\", backend=mml.Backend.TORCH),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f129844",
   "metadata": {},
   "source": [
    "With both stages defined, we construct the `ModelGraph`. \n",
    "\n",
    "`ModelGraph` requires only one argument:\n",
    "\n",
    "* `nodes`: A list of `ModelStage` or `FeatureSet` instances to incorporate into this ModelGraph. The order of the nodes does not matter, as long as all required inputs are included.\n",
    "\n",
    "The ModelGraph will handle all data routing, shape inference, and connection validation with the `.build_all()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a2c20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built node `Encoder` with shapes: (1, 101) -> (1, 32)\n",
      "Built node `Regressor` with shapes: (1, 32) -> (1, 1)\n"
     ]
    }
   ],
   "source": [
    "mg = ModelGraph(nodes=[charge_samples, ms_encoder, ms_regressor])\n",
    "mg.build_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33fd2d",
   "metadata": {},
   "source": [
    "We see that the missing input_shapes have been correctly inferred to match `charge_samples.feature_shape` and encoder output shape.\n",
    "\n",
    "\n",
    "ModelGraph has another useful validation function called `dummy_forward`.\n",
    "This performs a full forward pass of all connected stages with dummy batch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef15ed85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stage_results = mg.dummy_foward(batch_size=8)\n",
    "all_stage_results[\"Regressor\"].feature_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd884798",
   "metadata": {},
   "source": [
    "Great. We have a fully functional ModelGraph that correctly outputs a target with shape (1,1).\n",
    "\n",
    "Although this ModelGraph is very simple, as the number of nodes increase, it can be difficult to keep track of how all stages are connected.\n",
    "We can visuallize these node connections with the `visualize` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cc06917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "flowchart LR\n",
       "\tn0 e0@-->|\"(1, 101)\"| n1\n",
       "\tn1 e1@-->|\"(1, 32)\"| n2\n",
       "\n",
       "\tn0@{ label: \"FeatureSet<br>'ChargePulseFeatures'\", shape: rect }\n",
       "\tn1@{ label: \"ModelStage<br>'Encoder'\", shape: rect }\n",
       "\tn2@{ label: \"ModelStage<br>'Regressor'\", shape: rect }\n",
       "\tn0:::FeatureSet\n",
       "\tn1:::ModelStage\n",
       "\tn2:::ModelStage\n",
       "\tclassDef ModelStage stroke-width: 2px, stroke-dasharray: 0, stroke: #2962FF, fill: #BBDEFB, color:#000000;\n",
       "\tclassDef FeatureSet stroke-width: 2px, stroke-dasharray: 0, stroke: #AA00FF, fill: #E1BEE7, color:#000000;\n",
       "\n",
       "\tclassDef DashMediumAnimation stroke-dasharray: 9,5, stroke-dashoffset: 100, animation: dash 3s linear infinite;\n",
       "\tclass e0 DashMediumAnimation\n",
       "\tclass e1 DashMediumAnimation\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mg.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c5140",
   "metadata": {},
   "source": [
    "This concludes the **02_modelgraph_basics** notebook.\n",
    "\n",
    "The next tutorial explain the `Experiment` container and ModelGraph training/evaluation logic: [03_training_and_evaluation.ipynb](./03_training_and_evaluation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envModularML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
